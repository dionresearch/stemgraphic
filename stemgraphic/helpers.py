""" helpers.py

Helper functions for stemgraphic.
"""
from io import BytesIO
import numpy as np
import pandas as pd
import pickle
from warnings import warn

try:
    import dask.dataframe as dd
except ImportError:
    dd = False

try:
    import sixel
except ImportError:
    sixel = None


def jitter(data, scale):
    """Adds jitter to data, for display purpose

    :param data: numpy or pandas dataframe
    :param scale:
    :return:
    """
    return data + np.random.rand(len(data)) / (2 * scale)


def key_calc(stem, leaf, scale):
    """Calculates a value from a stem, a leaf and a scale.

    :param stem:
    :param leaf:
    :param scale:
    :return: calculated values
    """
    return (int(leaf) / 10 + int(stem)) * float(scale)


def legend(
    ax,
    x,
    y,
    asc,
    flip_axes,
    mirror,
    stem,
    leaf,
    scale,
    delimiter_color,
    aggregation=True,
    cur_font=None,
    display=10,
    pos="best",
    unit="",
):
    """ legend

    Builds a graphical legend for numerical stem-and-leaf plots.

    :param display:
    :param cur_font:
    :param ax:
    :param x:
    :param y:
    :param pos:
    :param asc:
    :param flip_axes:
    :param mirror:
    :param stem:
    :param leaf:
    :param scale:
    :param delimiter_color:
    :param unit:
    :param aggregation:
    """

    if pos is None:
        return
    aggr_fontsize = cur_font.get_size() - 2
    if (mirror and not flip_axes) or (flip_axes and not asc):
        ha = "right"
        formula = "{2}{1} =        x{0} = "
        offset = len(str(scale)) + 3.1 + (len(stem) + len(leaf)) / 1.7
        secondary = -2.5 if asc and flip_axes else -1.6
        key_text = "Key: leaf|stem{}".format("|aggr" if aggregation else "")
    else:
        ha = "left"
        formula = "  =         x{0} = {1}{2}"
        offset = 3.1
        secondary = 0.1
        key_text = "Key: {}stem|leaf".format("aggr|" if aggregation else "")
    start_at = (len(stem) * 2 + 11 + len(str(scale)) + len(leaf)) / 1.7
    if pos == "short":
        ax.text(
            x - start_at,
            y + 2,
            " x {}".format(scale),
            va="center",
            ha=ha,
            fontproperties=cur_font,
        )
    else:
        if aggregation:
            ax.text(
                x - start_at - 1,
                y + 2,
                key_text,
                va="center",
                ha=ha,
                fontproperties=cur_font,
            )
            ax.text(
                x - start_at - 2,
                y + 1,
                display,
                fontsize=aggr_fontsize - 2,
                va="center",
                ha=ha,
            )
        cur_font.set_weight("bold")
        ax.text(
            x - start_at - 1, y + 1, stem, va="center", ha=ha, fontproperties=cur_font
        )
        ax.text(
            x - start_at + (1 + len(leaf) + offset) / 1.7,
            y + 1,
            stem,
            va="center",
            ha=ha,
            fontproperties=cur_font,
        )
        cur_font.set_weight("normal")
        ax.text(
            x - start_at + (len(stem) + len(leaf)) / 1.7,
            y + 1,
            formula.format(scale, key_calc(stem, leaf, scale), unit),
            va="center",
            ha=ha,
            fontproperties=cur_font,
        )
        cur_font.set_style("italic")
        ax.text(
            x - start_at + 0.3,
            y + 1,
            leaf,
            bbox={"facecolor": "C0", "alpha": 0.15, "pad": 2},
            va="center",
            ha=ha,
            fontproperties=cur_font,
        )
        ax.text(
            x - start_at + (len(stem) + offset + len(leaf) + 0.6) / 1.7 + secondary,
            y + 1,
            "." + leaf,
            va="center",
            ha=ha,
            fontproperties=cur_font,
        )

        if flip_axes:
            ax.vlines(x - start_at, y + 0.5, y + 1.5, color=delimiter_color, alpha=0.7)
            if aggregation:
                ax.vlines(
                    x - start_at - 1, y + 0.5, y + 1.5, color=delimiter_color, alpha=0.7
                )
        else:
            ax.vlines(
                x - start_at + 0.1, y + 0.5, y + 1.5, color=delimiter_color, alpha=0.7
            )
            if aggregation:
                ax.vlines(
                    x - start_at - 1.1,
                    y + 0.5,
                    y + 1.5,
                    color=delimiter_color,
                    alpha=0.7,
                )


def min_max_count(x, column=0):
    """ min_max_count

    Handles min, max and count. This works on numpy, lists, pandas and dask dataframes.

    :param x: list, numpy array, series, pandas or dask dataframe
    :param column: future use
    :return: min, max and count
    """
    if dd and type(x) in (dd.core.DataFrame, dd.core.Series):
        omin, omax, count = dd.compute(x.min(), x.max(), x.count())
    elif type(x) in (pd.DataFrame, pd.Series):
        try:
            omin = x.min().values[0]
            omax = x.max().values[0]
        except AttributeError:
            omin = x.min()
            omax = x.max()
        count = len(x)
    else:
        omin = min(x)
        omax = max(x)
        count = len(x)

    return omin, omax, int(count)


def na_count(x, column=0):
    """ min_max_count

        Handles min, max and count. This works on numpy, lists, pandas and dask dataframes.

        :param x: list, numpy array, series, pandas or dask dataframe
        :param column: future use
        :return: all numpy nan count
        """
    val_missing = x.isnull().sum()
    return val_missing


def npy_save(path, array):
    """ npy_save

    saves numpy array to npy file on disk.

    :param path: path where to save npy file
    :param array: numpy array
    :return: path
    """
    if path[-4:] != ".npy":
        path += ".npy"
    with open(path, "wb+") as f:
        np.save(f, array, allow_pickle=False)
    return path


def npy_load(path):
    """ npy_load

    load numpy array (npy) file from disk.

    :param path: path to pickle file
    :return: numpy array
    """
    if path[-4:] != ".npy":
        warn("Not a numpy NPY file.")
        return None
    return np.load(path)


def pkl_save(path, array):
    """ pkl_save

    saves matrix or dataframe to pkl file on disk.

    :param path: path where to save pickle file
    :param array: matrix (array) or dataframe
    :return: path
    """
    if path[-4:] != ".pkl":
        path += ".pkl"
    with open(path, "wb+") as f:
        pickle.dump(array, f)
    return path


def pkl_load(path):
    """ pkl_load

    load matrix or dataframe pickle (pkl) file from disk.

    :param path: path to pickle file
    :return: matrix or dataframe
    """
    if path[-4:] != ".pkl":
        warn("Not a PKL file.")
        return None
    with open(path, "rb") as f:
        matrix = pickle.load(f)
    return matrix


def percentile(data, alpha):
    """ percentile

    :param data: list, numpy array, time series or pandas dataframe
    :param alpha: between 0 and 0.5 proportion to select on each side of the distribution
    :return: the actual value at that percentile
    """
    n = sorted(data)
    low = int(round(alpha * len(data) + 0.5))
    high = int(round((1 - alpha) * len(data) + 0.5))
    return n[low - 1], n[high - 1]


def savefig(plt):
    """ savefig

    Allows displaying a matplotlib figure to the console terminal. This requires pysixel to be pip installed.
    It also requires a terminal with Sixel graphic support, like DEC with graphic support, Linux xterm (started
    with -ti 340), MLTerm (multilingual terminal, available on Windows, Linux etc).

    This is called by the command line stem tool when using -o stdout and can also be used in an ipython session.

    :param plt: matplotlib pyplot
    :return:
    """
    buf = BytesIO()
    plt.savefig(buf)
    buf.seek(0)
    if sixel is None:
        warn("No sixel module available. Please install pysixel")
    writer = sixel.SixelWriter()
    writer.draw(buf)


def stack_columns(row):
    """ stack_columns

    stack multiple columns into a single stacked value

    :param row: a row of letters
    :return: stacked string
    """
    row = row.dropna()
    stack = ""
    for i, col in row.iteritems():
        stack += str(i) * int(col)
    return stack


#: Typographical apostrophe - ex: Iâ€™m, lâ€™arbre
APOSTROPHE = "â€™"

#: Straight quote mark - ex: 'INCONCEIVABLE'
QUOTE = "'"

#: Double straight quote mark
DOUBLE_QUOTE = '"'

#: empty
EMPTY = b" "

#: for typesetting overlap
OVER = b"\xd6\xb1"

#: Characters to filter. Does a relatively good job on a majority of texts
#: '- ' and 'â€“' is to skip quotes in many plays and dialogues in books, especially French.
CHAR_FILTER = [
    "\t",
    "\n",
    "\\",
    "/",
    "`",
    "*",
    "_",
    "{",
    "}",
    "[",
    "]",
    "(",
    ")",
    "<",
    ">",
    "#",
    "=",
    "+",
    "- ",
    "â€“",
    ".",
    ";",
    ":",
    "!",
    "?",
    "|",
    "$",
    QUOTE,
    DOUBLE_QUOTE,
    "â€¦",
]


#: Similar purpose to CHAR_FILTER, ut keeps the period. The last word of each sentence will end with a '.'
#: Useful for manipulating the dataframe returned by the various visualizations and ngram_data,
#: to break down frequencies by sentence instead of the full text or list.
NO_PERIOD_FILTER = [
    "\t",
    "\n",
    "\\",
    "/",
    "`",
    "*",
    "_",
    "{",
    "}",
    "[",
    "]",
    "(",
    ")",
    "<",
    ">",
    "#",
    "=",
    "+",
    "- ",
    "â€“",
    ";",
    ":",
    "!",
    "?",
    "|",
    "$",
    QUOTE,
    DOUBLE_QUOTE,
]


#: Default definition of standard letters
#: remove_accent has to be called explicitly for any of these letters to match their
#: accented counterparts
LETTERS = "abcdefghijklmnopqrstuvwxyz"

#: List of non alpha characters. Temporary - I want to balance flexibility with convenience, but
#: still looking at options.
NON_ALPHA = [
    "-",
    "+",
    "/",
    "[",
    "]",
    "_",
    "Â£",
    "1",
    "2",
    "3",
    "4",
    "5",
    "6",
    "7",
    "8",
    "9",
    "0",
    "!",
    "@",
    "#",
    "$",
    "%",
    "^",
    "&",
    "*",
    "(",
    ")",
    ";",
    QUOTE,
    DOUBLE_QUOTE,
    APOSTROPHE,
    EMPTY,
    OVER,
    "?",
    "Â¡",
    "Â¿",  # spanish
    "Â«",
    "Â»",
    "â€œ",
    "â€",
    "-",
    "â€”",
]

#: Charset unicode digit mappings
mapping = {
    "arabic": {
        "0": "Ù ",
        "1": "Ù¡",
        "2": "Ù¢",
        "3": "Ù£",
        "4": "Ù¤",
        "5": "Ù¥",
        "6": "Ù¦",
        "7": "Ù§",
        "8": "Ù¨",
        "9": "Ù©",
    },
    "arabic_r": {
        "0": "Ù ",
        "1": "Ù¡",
        "2": "Ù¢",
        "3": "Ù£",
        "4": "Ù¤",
        "5": "Ù¥",
        "6": "Ù¦",
        "7": "Ù§",
        "8": "Ù¨",
        "9": "Ù©",
    },
    "bold": {
        "0": "ğŸ",
        "1": "ğŸ",
        "2": "ğŸ",
        "3": "ğŸ‘",
        "4": "ğŸ’",
        "5": "ğŸ“",
        "6": "ğŸ”",
        "7": "ğŸ•",
        "8": "ğŸ–",
        "9": "ğŸ—",
    },
    "circled": {
        "0": "â“ª",
        "1": "â‘ ",
        "2": "â‘¡",
        "3": "â‘¢",
        "4": "â‘£",
        "5": "â‘¤",
        "6": "â‘¥",
        "7": "â‘¦",
        "8": "â‘§",
        "9": "â‘¨",
    },
    "default": {
        "0": "0",
        "1": "1",
        "2": "2",
        "3": "3",
        "4": "4",
        "5": "5",
        "6": "6",
        "7": "7",
        "8": "8",
        "9": "9",
    },
    "doublestruck": {
        "0": "ğŸ˜",
        "1": "ğŸ™",
        "2": "ğŸš",
        "3": "ğŸ›",
        "4": "ğŸœ",
        "5": "ğŸ",
        "6": "ğŸ",
        "7": "ğŸŸ",
        "8": "ğŸ ",
        "9": "ğŸ¡",
    },
    "fullwidth": {
        "0": "ï¼",
        "1": "ï¼‘",
        "2": "ï¼’",
        "3": "ï¼“",
        "4": "ï¼”",
        "5": "ï¼•",
        "6": "ï¼–",
        "7": "ï¼—",
        "8": "ï¼˜",
        "9": "ï¼™",
    },
    "gurmukhi": {
        "0": "à©¦",
        "1": "à©§",
        "2": "à©¨",
        "3": "à©©",
        "4": "à©ª",
        "5": "à©«",
        "6": "à©¬",
        "7": "à©­",
        "8": "à©®",
        "9": "à©¯",
    },
    "mono": {
        "0": "ğŸ¶",
        "1": "ğŸ·",
        "2": "ğŸ¸",
        "3": "ğŸ¹",
        "4": "ğŸº",
        "5": "ğŸ»",
        "6": "ğŸ¼",
        "7": "ğŸ½",
        "8": "ğŸ¾",
        "9": "ğŸ¿",
    },
    "nko": {
        "0": "ß€",
        "1": "ß",
        "2": "ß‚",
        "3": "ßƒ",
        "4": "ß„",
        "5": "ß…",
        "6": "ß†",
        "7": "ß‡",
        "8": "ßˆ",
        "9": "ß‰",
    },
    "rod": {
        "0": "â—¯",  # U+25EF LARGE CIRCLE
        "1": "ğ©",
        "2": "ğª",
        "3": "ğ«",
        "4": "ğ¬",
        "5": "ğ­",
        "6": "ğ®",
        "7": "ğ¯",
        "8": "ğ°",
        "9": "ğ±",
    },
    "roman": {
        "0": ".",  # No zero
        "1": "â… ",
        "2": "â…¡",
        "3": "â…¢",
        "4": "â…£",
        "5": "â…¤",
        "6": "â…¥",
        "7": "â…¦",
        "8": "â…§",
        "9": "â…¨",
    },
    "sans": {
        "0": "ğŸ¢",
        "1": "ğŸ£",
        "2": "ğŸ¤",
        "3": "ğŸ¥",
        "4": "ğŸ¦",
        "5": "ğŸ§",
        "6": "ğŸ¨",
        "7": "ğŸ©",
        "8": "ğŸª",
        "9": "ğŸ«",
    },
    "sansbold": {
        "0": "ğŸ¬",
        "1": "ğŸ­",
        "2": "ğŸ®",
        "3": "ğŸ¯",
        "4": "ğŸ°",
        "5": "ğŸ±",
        "6": "ğŸ²",
        "7": "ğŸ³",
        "8": "ğŸ´",
        "9": "ğŸµ",
    },
    "square": {
        "0": "ğŸŒ",
        "1": "ğŸ",
        "2": "ï¿­",
        "3": "â¬›",
        "4": "ğŸ“",
        "5": "ğŸ’",
        "6": "ğŸ‘",
        "7": "ğŸ",
        "8": "ğŸ",
        "9": "ğŸ",
    },
    "subscript": {
        "0": "â‚€",
        "1": "â‚",
        "2": "â‚‚",
        "3": "â‚ƒ",
        "4": "â‚„",
        "5": "â‚…",
        "6": "â‚†",
        "7": "â‚‡",
        "8": "â‚ˆ",
        "9": "â‚‰",
    },
    "tamil": {
        "0": "à¯¦",
        "1": "à¯§",
        "2": "à¯¨",
        "3": "à¯©",
        "4": "à¯ª",
        "5": "à¯«",
        "6": "à¯¬",
        "7": "à¯­",
        "8": "à¯®",
        "9": "à¯¯",
    },
}


#: Alphabet unicode mapping
alpha_mapping = {
    "boldsans": "ğ—”ğ—•ğ—–ğ——ğ—˜ğ—™ğ—šğ—›ğ—œğ—ğ—ğ—Ÿğ— ğ—¡ğ—¢ğ—£ğ—¤ğ—¥ğ—¦ğ—§ğ—¨ğ—©ğ—ªğ—«ğ—¬ğ—­ğ—®ğ—¯ğ—°ğ—±ğ—²ğ—³ğ—´ğ—µğ—¶ğ—·ğ—¸ğ—¹ğ—ºğ—»ğ—¼ğ—½ğ—¾ğ—¿ğ˜€ğ˜ğ˜‚ğ˜ƒğ˜„ğ˜…ğ˜†ğ˜‡",
    "bold": "ğ€ğğ‚ğƒğ„ğ…ğ†ğ‡ğˆğ‰ğŠğ‹ğŒğğğğğ‘ğ’ğ“ğ”ğ•ğ–ğ—ğ˜ğ™ğšğ›ğœğğğŸğ ğ¡ğ¢ğ£ğ¤ğ¥ğ¦ğ§ğ¨ğ©ğªğ«ğ¬ğ­ğ®ğ¯ğ°ğ±ğ²ğ³",
    "circle": "â’¶â’·â’¸â’¹â’ºâ’»â’¼â’½â’¾â’¿â“€â“â“‚â“ƒâ“„â“…â“†â“‡â“ˆâ“‰â“Šâ“‹â“Œâ“â“â“â“â“‘â“’â““â“”â“•â“–â“—â“˜â“™â“šâ“›â“œâ“â“â“Ÿâ“ â“¡â“¢â“£â“¤â“¥â“¦â“§â“¨â“©",
    "cursive": "ğ’œğµğ’ğ’Ÿğ¸ğ¹ğ’¢ğ»ğ¼ğ’¥ğ’¦ğ¿ğ‘€ğ’©ğ’ªğ’«ğ’¬ğ‘…ğ’®ğ’¯ğ’°ğ’±ğ’²ğ’³ğ’´ğ’µğ’¶ğ’·ğ’¸ğ’¹ğ‘’ğ’»ğ‘”ğ’½ğ’¾ğ’¿ğ“€ğ“ğ“‚ğ“ƒğ‘œğ“…ğ“†ğ“‡ğ“ˆğ“‰ğ“Šğ“‹ğ“Œğ“ğ“ğ“",
    "default": "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz",
    "doublestruck": "ğ”¸ğ”¹â„‚ğ”»ğ”¼ğ”½ğ”¾â„ğ•€ğ•ğ•‚ğ•ƒğ•„â„•ğ•†â„™â„šâ„ğ•Šğ•‹ğ•Œğ•ğ•ğ•ğ•â„¤ğ•’ğ•“ğ•”ğ••ğ•–ğ•—ğ•˜ğ•™ğ•šğ•›ğ•œğ•ğ•ğ•Ÿğ• ğ•¡ğ•¢ğ•£ğ•¤ğ•¥ğ•¦ğ•§ğ•¨ğ•©ğ•ªğ•«",
    "italicbold": "ğ‘¨ğ‘©ğ‘ªğ‘«ğ‘¬ğ‘­ğ‘®ğ‘¯ğ‘°ğ‘±ğ‘²ğ‘³ğ‘´ğ‘µğ‘¶ğ‘·ğ‘¸ğ‘¹ğ‘ºğ‘»ğ‘¼ğ‘½ğ‘¾ğ‘¿ğ’€ğ’ğ’‚ğ’ƒğ’„ğ’…ğ’†ğ’‡ğ’ˆğ’‰ğ’Šğ’‹ğ’Œğ’ğ’ğ’ğ’ğ’‘ğ’’ğ’“ğ’”ğ’•ğ’–ğ’—ğ’˜ğ’™ğ’šğ’›",
    "italicboldsans": "ğ˜¼ğ˜½ğ˜¾ğ˜¿ğ™€ğ™ğ™‚ğ™ƒğ™„ğ™…ğ™†ğ™‡ğ™ˆğ™‰ğ™Šğ™‹ğ™Œğ™ğ™ğ™ğ™ğ™‘ğ™’ğ™“ğ™”ğ™•ğ™–ğ™—ğ™˜ğ™™ğ™šğ™›ğ™œğ™ğ™ğ™Ÿğ™ ğ™¡ğ™¢ğ™£ğ™¤ğ™¥ğ™¦ğ™§ğ™¨ğ™©ğ™ªğ™«ğ™¬ğ™­ğ™®ğ™¯",
    "medieval": "ğ”„ğ”…â„­ğ”‡ğ”ˆğ”‰ğ”Šâ„Œâ„‘ğ”ğ”ğ”ğ”ğ”‘ğ”’ğ”“ğ””â„œğ”–ğ”—ğ”˜ğ”™ğ”šğ”›ğ”œâ„¨ğ”ğ”Ÿğ” ğ”¡ğ”¢ğ”£ğ”¤ğ”¥ğ”¦ğ”§ğ”¨ğ”©ğ”ªğ”«ğ”¬ğ”­ğ”®ğ”¯ğ”°ğ”±ğ”²ğ”³ğ”´ğ”µğ”¶ğ”·",
    "medievalbold": "ğ•¬ğ•­ğ•®ğ•¯ğ•°ğ•±ğ•²ğ•³ğ•´ğ•µğ•¶ğ•·ğ•¸ğ•¹ğ•ºğ•»ğ•¼ğ•½ğ•¾ğ•¿ğ–€ğ–ğ–‚ğ–ƒğ–„ğ–…ğ–†ğ–‡ğ–ˆğ–‰ğ–Šğ–‹ğ–Œğ–ğ–ğ–ğ–ğ–‘ğ–’ğ–“ğ–”ğ–•ğ––ğ–—ğ–˜ğ–™ğ–šğ–›ğ–œğ–ğ–ğ–Ÿ",
    "square": "ğŸ„°ğŸ„±ğŸ„²ğŸ„³ğŸ„´ğŸ„µğŸ„¶ğŸ„·ğŸ„¸ğŸ„¹ğŸ„ºğŸ„»ğŸ„¼ğŸ„½ğŸ„¾ğŸ„¿ğŸ…€ğŸ…ğŸ…‚ğŸ…ƒğŸ…„ğŸ……ğŸ…†ğŸ…‡ğŸ…ˆğŸ…‰ğŸ„°ğŸ„±ğŸ„²ğŸ„³ğŸ„´ğŸ„µğŸ„¶ğŸ„·ğŸ„¸ğŸ„¹ğŸ„ºğŸ„»ğŸ„¼ğŸ„½ğŸ„¾ğŸ„¿ğŸ…€ğŸ…ğŸ…‚ğŸ…ƒğŸ…„ğŸ……ğŸ…†ğŸ…‡ğŸ…ˆğŸ…‰",
    "square_inverted": "ğŸ…°ğŸ…±ğŸ…²ğŸ…³ğŸ…´ğŸ…µğŸ…¶ğŸ…·ğŸ…¸ğŸ…¹ğŸ…ºğŸ…»ğŸ…¼ğŸ…½ğŸ…¾ğŸ…¿ğŸ†€ğŸ†ğŸ†‚ğŸ†ƒğŸ†„ğŸ†…ğŸ††ğŸ†‡ğŸ†ˆğŸ†‰ğŸ…°ğŸ…±ğŸ…²ğŸ…³ğŸ…´ğŸ…µğŸ…¶ğŸ…·ğŸ…¸ğŸ…¹ğŸ…ºğŸ…»ğŸ…¼ğŸ…½ğŸ…¾ğŸ…¿ğŸ†€ğŸ†ğŸ†‚ğŸ†ƒğŸ†„ğŸ†…ğŸ††ğŸ†‡ğŸ†ˆğŸ†‰",
    "typewriter": "ğ™°ğ™±ğ™²ğ™³ğ™´ğ™µğ™¶ğ™·ğ™¸ğ™¹ğ™ºğ™»ğ™¼ğ™½ğ™¾ğ™¿ğš€ğšğš‚ğšƒğš„ğš…ğš†ğš‡ğšˆğš‰ğšŠğš‹ğšŒğšğšğšğšğš‘ğš’ğš“ğš”ğš•ğš–ğš—ğš˜ğš™ğššğš›ğšœğšğšğšŸğš ğš¡ğš¢ğš£",
}


def square_scale():
    """ square_scale

    Ordered key for 0-9 mapping to squares from tiny filled square to large hollow square.

    :return: scale from 0 to 9
    """
    return "ğŸŒ ğŸ ï¿­ â¬› ğŸ“ ğŸ’ ğŸ‘ ğŸ ğŸ ğŸ"


def available_charsets():
    """ available_alpha_charsets

        All supported unicode digit charsets, such as 'doublestruck' where 0 looks like: ğŸ˜

        :return: list of charset names
        """
    return list(mapping.keys())


def available_alpha_charsets():
    """ available_alpha_charsets

    All supported unicode alphabet charsets, such as 'doublestruck' where A looks like: ğ”¸

    :return: list of charset names
    """
    return list(alpha_mapping.keys())


def translate_alpha_representation(text, charset=None):
    """ translate_alpha_representation

    Replace the default (ASCII type) charset in a string with the equivalent in
    a different unicode charset.

    :param text: input string
    :param charset: unicode character set as defined by available_alpha_charsets
    :return: translated string
    """
    default = alpha_mapping["default"]
    lookup_charset = alpha_mapping[charset]

    lookup = dict(zip(default, lookup_charset))

    if charset == "arabic_r":
        if text[-1] != "|":
            text_string = text[::-1]
        else:
            text_string = text[text.find("|") - 1 :: -1] + text[-1:]
    else:
        text_string = text

    return "".join([lookup.get(c, c) for c in text_string])


def translate_representation(text, charset=None, index=None, zero_blank=None):
    """ translate_representation

    Replace the default (ASCII type) digit glyphs in a string with the equivalent in
    a different unicode charset.

    :param text: input string
    :param charset: unicode character set as defined by available_alpha_charsets
    :param index: correspond to which item in a list we are looking at, for zero_blank
    :param zero_blank: will blank 0 if True, unless we are looking at header (row index < 2)
    :return: translated string
    """
    lookup = mapping[charset]
    if charset == "arabic_r":
        if text[-1] != "|":
            text_string = text[::-1]
        else:
            text_string = text[text.find("|") - 1 :: -1] + text[-1:]
    else:
        text_string = text
    if index > 1 and zero_blank:
        text_string = text_string[:4] + text_string[4:].replace(" 0", "  ").replace(
            " nan", "    "
        )
    return "".join([lookup.get(c, c) for c in text_string])
